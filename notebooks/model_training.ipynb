{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:51.567017Z",
     "start_time": "2025-08-30T18:56:51.213455Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:51.573929Z",
     "start_time": "2025-08-30T18:56:51.571471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ],
   "id": "1ff8e6124afacac6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:52.767446Z",
     "start_time": "2025-08-30T18:56:51.577019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.model import train, test\n",
    "from src.model.model import (\n",
    "    LightGBMModel,\n",
    "    XGBoostModel,\n",
    "    CatBoostModel,\n",
    "    LogisticRegressionModel,\n",
    "    StackingEnsemble\n",
    ")\n",
    "from src.utils import get_config"
   ],
   "id": "e65d6d2b24c3ac66",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:52.777333Z",
     "start_time": "2025-08-30T18:56:52.771300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = get_config.read_yaml_from_main()\n",
    "print(\"Configuration loaded successfully!\")"
   ],
   "id": "f8661607222d67d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:52.794802Z",
     "start_time": "2025-08-30T18:56:52.780278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_model(model_name):\n",
    "    model_dir = Path(config['paths']['model_data_directory'])\n",
    "    model_path = model_dir / f\"{model_name}_model.joblib\"\n",
    "    train.train_model(model_name, model_path)\n",
    "    test.test_model(model_name)"
   ],
   "id": "b04221cbbbf8e1ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:56:59.718894Z",
     "start_time": "2025-08-30T18:56:52.798401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'lightgbm'\n",
    "run_model(model_name)"
   ],
   "id": "8cfd708239eff64e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: lightgbm ---\n",
      "--- Fitting LightGBMModel ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15686\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Validation ROC AUC: 0.6125\n",
      "Validation PR AUC (AUC-PR): 0.1277\n",
      "Model saved to ..\\models\\lightgbm_model.joblib\n",
      "--- Testing Model from: ../models/lightgbm_model.joblib ---\n",
      "\n",
      "--- Test Set Performance ---\n",
      "Test ROC AUC: 0.6133\n",
      "Test PR AUC: 0.1268\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:57:04.438440Z",
     "start_time": "2025-08-30T18:56:59.725415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'xgboost'\n",
    "run_model(model_name)"
   ],
   "id": "5deb95454ff25d57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: xgboost ---\n",
      "--- Fitting XGBoostModel ---\n",
      "Validation ROC AUC: 0.5797\n",
      "Validation PR AUC (AUC-PR): 0.1156\n",
      "Model saved to ..\\models\\xgboost_model.joblib\n",
      "--- Testing Model from: ../models/xgboost_model.joblib ---\n",
      "\n",
      "--- Test Set Performance ---\n",
      "Test ROC AUC: 0.5875\n",
      "Test PR AUC: 0.1158\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:57:29.689375Z",
     "start_time": "2025-08-30T18:57:04.442384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'catboost'\n",
    "run_model(model_name)"
   ],
   "id": "3e377e92357517e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: catboost ---\n",
      "--- Fitting CatBoostModel ---\n",
      "Validation ROC AUC: 0.5856\n",
      "Validation PR AUC (AUC-PR): 0.1205\n",
      "Model saved to ..\\models\\catboost_model.joblib\n",
      "--- Testing Model from: ../models/catboost_model.joblib ---\n",
      "\n",
      "--- Test Set Performance ---\n",
      "Test ROC AUC: 0.5948\n",
      "Test PR AUC: 0.1211\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:57:33.940258Z",
     "start_time": "2025-08-30T18:57:29.694458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'logistic_regression'\n",
    "run_model(model_name)"
   ],
   "id": "94811a29876db1ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: logistic_regression ---\n",
      "--- Fitting LogisticRegressionModel ---\n",
      "Validation ROC AUC: 0.6114\n",
      "Validation PR AUC (AUC-PR): 0.1242\n",
      "Model saved to ..\\models\\logistic_regression_model.joblib\n",
      "--- Testing Model from: ../models/logistic_regression_model.joblib ---\n",
      "\n",
      "--- Test Set Performance ---\n",
      "Test ROC AUC: 0.6140\n",
      "Test PR AUC: 0.1263\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T18:58:05.319875Z",
     "start_time": "2025-08-30T18:57:33.944029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'ensemble'\n",
    "run_model(model_name)"
   ],
   "id": "a46444a23db73b63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: ensemble ---\n",
      "--- Fitting Stacking Ensemble ---\n",
      "Fitting base model: LightGBMModel\n",
      "--- Fitting LightGBMModel ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15686\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fitting base model: XGBoostModel\n",
      "--- Fitting XGBoostModel ---\n",
      "Fitting base model: CatBoostModel\n",
      "--- Fitting CatBoostModel ---\n",
      "Fitting base model: LogisticRegressionModel\n",
      "--- Fitting LogisticRegressionModel ---\n",
      "Fitting meta-learner...\n",
      "--- Ensemble Fitting Complete ---\n",
      "Validation ROC AUC: 0.5483\n",
      "Validation PR AUC (AUC-PR): 0.1002\n",
      "Ensemble model saved to ..\\models\\ensemble_model.joblib\n",
      "--- Testing Model from: ../models/ensemble_model.joblib ---\n",
      "\n",
      "--- Test Set Performance ---\n",
      "Test ROC AUC: 0.5592\n",
      "Test PR AUC: 0.1018\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-30T18:58:05.325917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "# --- This code goes in a new cell in your notebook ---\n",
    "\n",
    "def objective(trial):\n",
    "    # 1. Define the hyperparameters to search\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'rocauc', # Optimize directly for PR AUC\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    data_dir = config['paths']['processed_data_directory']\n",
    "    val_df = pd.read_csv(data_dir + \"/clean_val_data.csv\")\n",
    "\n",
    "    # 2. Prepare Data\n",
    "    id_col = config['data']['id']\n",
    "    target_col = config['data']['target']\n",
    "\n",
    "    X_val = val_df.drop(columns=[id_col, target_col])\n",
    "    y_val = val_df[target_col]\n",
    "    model_name = 'ensemble'\n",
    "    model_dir = Path(config['paths']['model_data_directory'])\n",
    "    model_path = model_dir / f\"{model_name}_model.joblib\"\n",
    "    train.train_model(model_name, model_path)\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # 3. Evaluate on the validation set and return the score\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, val_preds)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "# --- Create and run the study ---\n",
    "# We want to MAXIMIZE the PR AUC, so the direction is 'maximize'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10) # Run 50 trials\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# You can now retrain your model using these best parameters."
   ],
   "id": "a2f83c1de8e3d954",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 00:28:05,406] A new study created in memory with name: no-name-f4113462-db42-479d-9426-dca8e7b17c08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: ensemble ---\n",
      "--- Fitting Stacking Ensemble ---\n",
      "Fitting base model: LightGBMModel\n",
      "--- Fitting LightGBMModel ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15686\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fitting base model: XGBoostModel\n",
      "--- Fitting XGBoostModel ---\n",
      "Fitting base model: CatBoostModel\n",
      "--- Fitting CatBoostModel ---\n",
      "Fitting base model: LogisticRegressionModel\n",
      "--- Fitting LogisticRegressionModel ---\n",
      "Fitting meta-learner...\n",
      "--- Ensemble Fitting Complete ---\n",
      "Validation ROC AUC: 0.5483\n",
      "Validation PR AUC (AUC-PR): 0.1002\n",
      "Ensemble model saved to ..\\models\\ensemble_model.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 00:28:39,180] Trial 0 finished with value: 0.5482650324201116 and parameters: {'n_estimators': 1916, 'learning_rate': 0.23270434773697649, 'num_leaves': 117, 'max_depth': 4, 'min_child_samples': 129, 'feature_fraction': 0.6452104266009124, 'bagging_fraction': 0.9490543271504135, 'bagging_freq': 5, 'lambda_l1': 1.1093170401418448e-08, 'lambda_l2': 6.4644230724332e-07}. Best is trial 0 with value: 0.5482650324201116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing to Train Model: ensemble ---\n",
      "--- Fitting Stacking Ensemble ---\n",
      "Fitting base model: LightGBMModel\n",
      "--- Fitting LightGBMModel ---\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 17377, number of negative: 197880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15686\n",
      "[LightGBM] [Info] Number of data points in the train set: 215257, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fitting base model: XGBoostModel\n",
      "--- Fitting XGBoostModel ---\n",
      "Fitting base model: CatBoostModel\n",
      "--- Fitting CatBoostModel ---\n",
      "Fitting base model: LogisticRegressionModel\n",
      "--- Fitting LogisticRegressionModel ---\n",
      "Fitting meta-learner...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2f79a5565ffb18f3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
